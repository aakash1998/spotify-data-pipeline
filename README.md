# ğŸ§ Spotify ETL Data Pipeline (AWS + Snowflake + PySpark)

This project demonstrates a full **end-to-end, automated data engineering pipeline** built using AWS services, PySpark (Glue), and Snowflake. It extracts data from the **Spotify API**, transforms it using **AWS Glue**, and loads it into a **Snowflake** data warehouse for analytics.

---

## ğŸ“Š Project Architecture

```
Spotify API â†’ Lambda â†’ S3 (raw) â†’ Glue Job (ETL) â†’ S3 (transformed) â†’ Snowpipe â†’ Snowflake Tables
```

---

## ğŸ§± Tech Stack

- **Data Ingestion**: Spotify API, AWS Lambda, Boto3
- **Storage**: AWS S3
- **Data Transformation**: AWS Glue (PySpark)
- **Orchestration**: S3 Trigger + AWS Lambda
- **Data Warehouse**: Snowflake (Snowpipe)
- **Automation**: Entire pipeline is triggered and handled automatically

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ lambda_function/
â”‚   â””â”€â”€ spotify_etl_lambda.py         # Lambda function to pull data from Spotify API
â”œâ”€â”€ glue_jobs/
â”‚   â””â”€â”€ transform_spotify_data.py     # PySpark ETL script for AWS Glue
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ create_tables.sql             # Snowflake table schema
â”‚   â””â”€â”€ create_snowpipe.sql           # Snowpipe config for automated loads
â”œâ”€â”€ s3_structure/
â”‚   â””â”€â”€ raw_data/
â”‚       â””â”€â”€ to_processed/
â”‚       â””â”€â”€ processed/
â”‚   â””â”€â”€ transformed_data/
â”‚       â””â”€â”€ album_data/
â”‚       â””â”€â”€ artist_data/
â”‚       â””â”€â”€ song_data/
â””â”€â”€ README.md
```

---

## ğŸš€ Pipeline Breakdown

### 1. ğŸ§ **Spotify API Ingestion with Lambda**

- Extracts recent track data from the Spotify API.
- Lambda function is deployed with environment variables for secure API credentials.
- Data is saved to S3 in `raw_data/to_processed/` as `.json`.

âœ… Triggered automatically by **time-based CloudWatch schedule** or **manually**.

---

### 2. ğŸ—‚ï¸ **S3 Buckets Structure**

- `raw_data/to_processed/`: Raw incoming Spotify data
- `raw_data/processed/`: Archive of processed raw files
- `transformed_data/`: Final cleaned & transformed data output from Glue

---

### 3. ğŸ§ª **Data Transformation with AWS Glue (PySpark)**

- Glue job reads JSON files from S3.
- Parses, normalizes, and extracts:
  - ğŸµ `Songs` (name, duration, popularity, artist, album)
  - ğŸ¨ `Artists` (id, name, external links)
  - ğŸ’¿ `Albums` (name, release date, track count)
- Transformed data saved as CSV to `transformed_data/` folder in S3.

âœ… Fully automated and scalable with PySpark.

---

### 4. â„ï¸ **Snowflake Integration with Snowpipe**

- Snowflake tables created to store Album, Artist, and Song data.
- Snowpipe listens to the S3 bucket and auto-loads new transformed CSV files.
- Ensures near real-time ingestion into Snowflake for analytics.

âœ… Automatically triggered when new files land in S3.

---

## ğŸ“¦ Example Tables in Snowflake

| Table Name       | Description                        |
|------------------|------------------------------------|
| `spotify_albums` | Album metadata                     |
| `spotify_artists`| Artist metadata                    |
| `spotify_songs`  | Track metadata (linked to artist/album) |

---

## âš™ï¸ How to Run This Project

### ğŸ” Prerequisites

- AWS account with S3, Lambda, Glue access
- Snowflake account
- Spotify Developer API keys
- IAM roles for Glue and Lambda (with proper permissions)

---

### ğŸ§ª Deployment Steps

1. **Set up AWS S3 buckets**
   - Create required folders as per structure above.

2. **Deploy Lambda Function**
   - Use `spotify_etl_lambda.py`
   - Set environment variables for Spotify keys
   - Add CloudWatch trigger (optional)

3. **Create Glue Job**
   - Use `transform_spotify_data.py`
   - Set the script path in the Glue job
   - Schedule via trigger or run on file arrival

4. **Deploy Snowflake Tables + Snowpipe**
   - Use `create_tables.sql` and `create_snowpipe.sql`
   - Ensure Snowpipe has access to your S3 bucket via external stage

5. **Automate Move/Delete**
   - Handled within the Glue job using boto3 after transformation

---

## ğŸ¯ Features

- âœ… Scalable Spark-based ETL
- âœ… Serverless ingestion with Lambda
- âœ… Modular & clean PySpark logic
- âœ… Snowflake integration via Snowpipe
- âœ… Automated cleanup & data lifecycle
- âœ… Real-time-ready analytics layer

---

## ğŸ§  Author

Aakash Patel
